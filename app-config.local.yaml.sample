# Backstage override configuration for your local development environment
ai_server:
  url: "http://localhost:3001" # Specifies where top find the Chatbot UI GUI (default)
  # url: "http://localhost:3100" # Specifies where to find the Ollama Web UI 
  # url: "http://localhost:7860" # Specifies where to find the Text Generation WebUI
  # url: "http://localhost:3456" # Specifies where to find the Big-AGI UI
  # url: "https://vllm.libra.decc.vmware.com/" # Specifies where to find the VMware VLLM Server
   
catalog:
  locations:
    - type: url
      target: https://github.com/benwilcock/backstagecon-2023/blob/main/backchat-catalog.yaml
  rules:
    - allow: [Component, API, Resource, System, Domain, Location, Group, User]
